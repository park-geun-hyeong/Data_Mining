{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-geun-hyeong/Data_Mining/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X9Ml1sjUpT8"
      },
      "source": [
        "path =  '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgolwlz-mSqf"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYry8GiCm-0B"
      },
      "source": [
        "### Spark 3.2 Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuqvrfGHmeTC"
      },
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYiUyLRciTeu"
      },
      "source": [
        "Set the environment path which enables you to run Pyspark in the Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME2tRXD0m8xu"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0khb1gqiXZW"
      },
      "source": [
        "Findspark: Find the locatation of the spark in the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiMUBML0nFON"
      },
      "source": [
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T2Jj4emfxOJ"
      },
      "source": [
        "The entry point into all functionality in Spark is the SparkSession class. To create a basic SparkSession, just use SparkSession.builder():\n",
        "\n",
        "Entry points\n",
        "- Newer entry point: SparkSession (Introduced at Spark 2.0)\n",
        "- Older entry points: SparkContext, SQLContext, and HiveContext \n",
        "\n",
        "SparkSession \n",
        "- Replace SQLContext and HiveContext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWXPOwdgUeHb"
      },
      "source": [
        "from pyspark.sql import SparkSession \n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Example\") \\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0hYROFnFuF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d91825ce-564b-4354-c898-5a87899c0e4e"
      },
      "source": [
        "spark.version"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.0'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1qMyU39glOp"
      },
      "source": [
        "Access to SparkContext as follow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gA-X2z_aWTG"
      },
      "source": [
        "sc = spark.sparkContext  # same as spark._sc"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nGO_jVnb0G5"
      },
      "source": [
        "#### Two ways to create RDDs\n",
        "- Parallelizing an existing collection in your driver program\n",
        "- Referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovHhzIWHaWPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9315f4-11c2-4312-b814-10f6df451890"
      },
      "source": [
        "data = list(range(10000))\n",
        "distData = sc.parallelize(data)  # distributed dataset\n",
        "distData"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oL4HV_DaWL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e527593d-425e-43f0-a8a1-d999939190ca"
      },
      "source": [
        "distData.reduce(lambda a, b: a + b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49995000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCuS-IWtaWIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0557fa-198b-42e1-f0ef-d94b5afb5782"
      },
      "source": [
        "from operator import add\n",
        "distData.reduce(add)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49995000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvtn-qdLY30X"
      },
      "source": [
        "## Text File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmObOdOUGWCx"
      },
      "source": [
        "lines = sc.textFile(path + \"anna.txt\")\n",
        "# lines = sc.textFile(\"hdfs://...\") ## Hadoop file system\n",
        "\n",
        "# rdd = sc.textFile('BostonHousing.csv')\n",
        "# df = spark.read.csv(rdd)\n",
        "lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0Ga7EZaWAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc7db42-51af-44aa-ef6e-616ba3b7f4c3"
      },
      "source": [
        "lineLengths = lines.map(lambda s: len(s))\n",
        "lineLengths"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[15] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK2GsNVcmQCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c42e318-97ff-4690-dbb3-dcdbaa49a13b"
      },
      "source": [
        "totalLength = lineLengths.reduce(add)\n",
        "totalLength"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1944960"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ9e6OUirCo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e0c3b0-a8a5-4ca5-d9d9-3eb92cd93ba7"
      },
      "source": [
        "lineCounts = lines.map(lambda s: len(s.split()))\n",
        "wordCounts = lineCounts.reduce(add)\n",
        "wordCounts"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352929"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEFfZAUH4N4"
      },
      "source": [
        "### Word count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3yL8mPbcPzg"
      },
      "source": [
        "lines = sc.textFile(path + \"anna.txt\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n21-J5tlG-Xn"
      },
      "source": [
        "# map: Return a new distributed dataset formed by passing \n",
        "#      each element of the source through a function func.\n",
        "# flatMap: Similar to map, but each input item can be \n",
        "#          mapped to 0 or more output items \n",
        "counts = lines.flatMap(lambda line: line.split(' ')) \\\n",
        "              .map(lambda word: (word, 1)) \\\n",
        "              .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# return all the elements of the dataset as an array\n",
        "counts.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQyMnPsrIr1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8928f8b5-b196-4e5a-96c8-91d9976569c8"
      },
      "source": [
        "counts = lines.flatMap(lambda line: line.split(' ')) \\\n",
        "              .map(lambda word: (word, 1)) \\\n",
        "              .reduceByKey(lambda a, b: a + b) \\\n",
        "              .sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "counts.take(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 16498), ('and', 11610), ('to', 9989), ('', 9036), ('of', 8594)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guyutcbDJZ02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e09699-99c2-4621-9479-c567fb55c005"
      },
      "source": [
        "counts = lines.flatMap(lambda line: line.split(' ')) \\\n",
        "              .map(lambda word: (word, 1)) \\\n",
        "              .reduceByKey(lambda a, b: a + b) \\\n",
        "              .sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "counts.take(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 16498), ('and', 11610), ('to', 9989), ('', 9036), ('of', 8594)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4epOsTHRP0Q"
      },
      "source": [
        "Passing Functions to Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7FBidfGcP_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc08df74-4553-4486-d3e3-da71f767bcbd"
      },
      "source": [
        "def containPrince(line):\n",
        "    return \"Prince\" in line\n",
        "\n",
        "rdd = lines.filter(containPrince) \\\n",
        "           .collect()\n",
        "rdd[:5]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Three days after the quarrel, Prince Stepan Arkadyevitch',\n",
              " 'prepared for the university with the young Prince Shtcherbatsky, the',\n",
              " 'the young Princess Shtcherbatskaya an offer of marriage; in all',\n",
              " '\"Delighted to see you,\" said Princess Shtcherbatskaya. \"On Thursdays we',\n",
              " 'directly; Prince Golistin with a lady. Fresh oysters have come in.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVxW6KLQdcH-",
        "outputId": "8186df8d-d4b6-4d62-bb3e-8e5204577f99"
      },
      "source": [
        "lines.filter(containPrince).flatMap(lambda line: line.split()).map(lambda word: (word,1)).collect()[:5]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Three', 1), ('days', 1), ('after', 1), ('the', 1), ('quarrel,', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxmN7SrOeMFz",
        "outputId": "0d5caab9-37cf-44bf-dec1-ca814f4bb0f4"
      },
      "source": [
        "lines.filter(containPrince) \\\n",
        "     .flatMap(lambda line: line.split()) \\\n",
        "     .map(lambda word: (word,1)) \\\n",
        "     .reduceByKey(lambda a,b :a+b) \\\n",
        "     .sortBy(lambda x: x[1], ascending=False) \\\n",
        "     .collect()[:5]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Princess', 125), ('the', 78), ('to', 42), ('of', 36), ('and', 33)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_bXWCCRLit6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4e0526-31fd-4155-ddf8-4d99ae28411d"
      },
      "source": [
        "rdd = lines.filter(containPrince) \\\n",
        "           .flatMap(lambda line: line.split(' ')) \\\n",
        "           .map(lambda word: (word, 1)) \\\n",
        "           .count() ## 합치기 전에 전체 word key-value 쌍 count 해주면 결국엔 전체 단어 개수가 출력된다.\n",
        "rdd"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1691"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbQLiZpMOxVV"
      },
      "source": [
        "Creating DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTgIOIWROuvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147e92ab-7968-476b-d89d-3eacb2b02451"
      },
      "source": [
        "df = spark.read.json(path+\"people.json\")\n",
        "# Displays the content of the DataFrame to stdout\n",
        "df.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|null|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao256wPzO0kv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a48ca5d-9c83-4188-82d0-64dc23af38ce"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waCYe289O41o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16086e9f-c8d2-44fd-f9d6-baa4cc47b7e6"
      },
      "source": [
        "# Select only the \"name\" column\n",
        "df.select(\"name\").show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|   name|\n",
            "+-------+\n",
            "|Michael|\n",
            "|   Andy|\n",
            "| Justin|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDa9IhuUO4t2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2403b0-8cf1-42b5-b0aa-33b8831fcc91"
      },
      "source": [
        "# Select everybody, but increment the age by 1\n",
        "df.select(df['name'], df['age'] + 1).show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|   name|(age + 1)|\n",
            "+-------+---------+\n",
            "|Michael|     null|\n",
            "|   Andy|       31|\n",
            "| Justin|       20|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZD9q-ntO4k-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7412a50-e05e-4820-fc92-cf2bc52d84ad"
      },
      "source": [
        "# Select people older than 21\n",
        "df.filter(df['age'] > 21).show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "|age|name|\n",
            "+---+----+\n",
            "| 30|Andy|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzMiFve0O4Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d2e0bc-7a26-4182-812e-187d3871a0b4"
      },
      "source": [
        "# Count people by age\n",
        "df.groupBy(\"age\").count().show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age|count|\n",
            "+----+-----+\n",
            "|  19|    1|\n",
            "|  30|    1|\n",
            "|null|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8RK6AmmPJtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f213ee8c-89b0-406f-acae-d64f92cc8fb2"
      },
      "source": [
        "# Register the DataFrame as a SQL temporary view\n",
        "df.createOrReplaceTempView(\"people\") ## table name\n",
        "\n",
        "sqlDF = spark.sql(\"SELECT * FROM people\")\n",
        "sqlDF.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|null|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNFpjZsawo6i"
      },
      "source": [
        "### DataFrame Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTp6H5zEwnPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9cb05c-87bf-496f-d093-af2d9348de0c"
      },
      "source": [
        "from datetime import datetime, date\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "\n",
        "df"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vO6L3mwnJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a749ef-ebe7-495d-d9d9-ce9c67e5c3d6"
      },
      "source": [
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='a long, b double, c string, d date, e timestamp')\n",
        "df"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmOifVtbwnC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1a32b0-8827-4d23-814b-65ab04c5cab7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pandas_df = pd.DataFrame({\n",
        "    'a': [1, 2, 3],\n",
        "    'b': [2., 3., 4.],\n",
        "    'c': ['string1', 'string2', 'string3'],\n",
        "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
        "})\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "df"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-48iVkBwm84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "fd3bf9b9-2e43-4b02-bba3-eadb03084b67"
      },
      "source": [
        "pandas_df"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>string1</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>2000-01-01 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>string2</td>\n",
              "      <td>2000-02-01</td>\n",
              "      <td>2000-01-02 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>string3</td>\n",
              "      <td>2000-03-01</td>\n",
              "      <td>2000-01-03 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a    b        c           d                   e\n",
              "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
              "1  2  3.0  string2  2000-02-01 2000-01-02 12:00:00\n",
              "2  3  4.0  string3  2000-03-01 2000-01-03 12:00:00"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ9mSTz_N7Mf"
      },
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czpTS6XDgYS0"
      },
      "source": [
        "svm_df = pd.read_csv(path+ 'sample_svm_data.txt', sep=' ', header =None)\n",
        "label = svm_df.iloc[:,0].values.tolist()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CMP4zb1Ig-gm",
        "outputId": "50760666-7b9d-471f-ebf7-47dfe0d5c46a"
      },
      "source": [
        "svm_df"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.520784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.061394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.061394</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.055003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.061394</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.055003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>1</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.004684</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>2.122974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>1</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.520784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.055003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.619965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.122974</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>2.228387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.055003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>322 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0         1         2         3         4   ...        12   13   14   15   16\n",
              "0     1  0.000000  2.520784  0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "1     0  2.857738  0.000000  0.000000  2.619965  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "2     0  2.857738  0.000000  2.061394  0.000000  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "3     1  0.000000  0.000000  2.061394  2.619965  ...  2.055003  0.0  0.0  0.0  0.0\n",
              "4     1  2.857738  0.000000  2.061394  2.619965  ...  2.055003  0.0  0.0  0.0  0.0\n",
              "..   ..       ...       ...       ...       ...  ...       ...  ...  ...  ...  ...\n",
              "317   1  2.857738  0.000000  0.000000  2.619965  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "318   0  2.857738  0.000000  0.000000  2.619965  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "319   1  2.857738  0.000000  0.000000  2.619965  ...  0.000000  0.0  0.0  0.0  0.0\n",
              "320   1  0.000000  2.520784  0.000000  2.619965  ...  2.055003  0.0  0.0  0.0  0.0\n",
              "321   1  2.857738  0.000000  0.000000  2.619965  ...  2.055003  0.0  0.0  0.0  0.0\n",
              "\n",
              "[322 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFh-gHKznrYl"
      },
      "source": [
        "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "\n",
        "# Load and parse the data\n",
        "def parsePoint(line):\n",
        "    values = [float(x) for x in line.split(' ')]\n",
        "    return LabeledPoint(values[0], values[1:])\n",
        "\n",
        "data = sc.textFile(path + \"sample_svm_data.txt\")\n",
        "parsedData = data.map(parsePoint)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFHg-aHEhQX7",
        "outputId": "b56aec61-3aa0-47b1-986d-156f7031f84a"
      },
      "source": [
        "parsedData.collect()[0]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabeledPoint(1.0, [0.0,2.52078447201548,0.0,0.0,0.0,2.004684436494304,2.000347299268466,0.0,2.228387042742021,2.228387042742023,0.0,0.0,0.0,0.0,0.0,0.0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaT0ul7sORTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e14dde-beac-4a8c-ffee-d3a1e0b7bccc"
      },
      "source": [
        "# Build the model\n",
        "model = SVMWithSGD.train(parsedData, iterations=100)\n",
        "\n",
        "# Evaluating the model on training data\n",
        "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
        "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\n",
        "print(\"Training Error = \" + str(trainErr))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Error = 0.38198757763975155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99iju87eOyzA"
      },
      "source": [
        "## K-means clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wrJpHMPORNA"
      },
      "source": [
        "from pyspark.ml.clustering import KMeans"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEZm28tAOmZe"
      },
      "source": [
        "dataset = spark.read.format(\"libsvm\").load(path + \"sample_kmeans_data.txt\")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBpcLJFpORGS"
      },
      "source": [
        "# Trains a k-means model.\n",
        "kmeans = KMeans().setK(2).setSeed(1)\n",
        "model = kmeans.fit(dataset)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfG29O_rOQzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdfe1bb-da61-4050-e645-66ed19aca5d8"
      },
      "source": [
        "# Make predictions\n",
        "predictions = model.transform(dataset)\n",
        "predictions.show()  # prediction.toPandas()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+----------+\n",
            "|label|            features|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|  0.0|           (3,[],[])|         1|\n",
            "|  1.0|(3,[0,1,2],[0.1,0...|         1|\n",
            "|  2.0|(3,[0,1,2],[0.2,0...|         1|\n",
            "|  3.0|(3,[0,1,2],[9.0,9...|         0|\n",
            "|  4.0|(3,[0,1,2],[9.1,9...|         0|\n",
            "|  5.0|(3,[0,1,2],[9.2,9...|         0|\n",
            "+-----+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky0zgK-_LSAj"
      },
      "source": [
        "#### Session stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqftjFRMOhXD"
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}